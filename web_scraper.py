#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Webç‰ˆå¾®åšçˆ¬è™« - æ”¯æŒå…³é”®è¯æœç´¢å’ŒWebç•Œé¢
"""

import ssl
import urllib.request
import json
import re
import os
import glob
from datetime import datetime
import time
import zipfile
import base64


class WebWeiboScraper:
    def __init__(self, user_id, user_name, start_date, end_date, keywords=None, max_pages=10, request_delay=2, output_dir="weibo_output"):
        # åŸºæœ¬é…ç½®
        self.user_id = user_id
        self.user_name = user_name
        self.start_date = start_date
        self.end_date = end_date
        self.keywords = keywords or []  # å…³é”®è¯åˆ—è¡¨
        self.max_pages = max_pages
        self.request_delay = request_delay
        self.output_dir = output_dir
        
        # SSLè®¾ç½®
        self.ssl_context = ssl.create_default_context()
        self.ssl_context.check_hostname = False
        self.ssl_context.verify_mode = ssl.CERT_NONE
        
        # HTTPè¯·æ±‚å¤´
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (iPhone; CPU iPhone OS 15_0 like Mac OS X) AppleWebKit/605.1.15',
            'Accept': 'application/json, text/plain, */*',
            'Referer': f'https://m.weibo.cn/u/{self.user_id}',
        }
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        self.reports_dir = os.path.join(self.output_dir, "reports")
        self.images_dir = os.path.join(self.output_dir, "images")
        self.data_dir = os.path.join(self.output_dir, "data")
        
        for directory in [self.output_dir, self.reports_dir, self.images_dir, self.data_dir]:
            os.makedirs(directory, exist_ok=True)
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'total_weibos': 0,
            'filtered_weibos': 0,
            'images_downloaded': 0,
            'keyword_matches': 0,
            'pages_processed': 0
        }

    def format_chinese_date(self, date_str):
        """å°†æ—¥æœŸè½¬æ¢ä¸ºä¸­æ–‡æ ¼å¼"""
        try:
            if any(day in date_str for day in ['Thu', 'Fri', 'Mon', 'Tue', 'Wed', 'Sat', 'Sun']):
                date_str = re.sub(r'\s+\+\d{4}', '', date_str)
                dt = datetime.strptime(date_str, '%a %b %d %H:%M:%S %Y')
                return f"{dt.year}å¹´{dt.month}æœˆ{dt.day}æ—¥"
            else:
                return date_str
        except:
            return date_str

    def is_in_date_range(self, date_str):
        """æ£€æŸ¥æ—¥æœŸæ˜¯å¦åœ¨æŒ‡å®šèŒƒå›´å†…"""
        try:
            if any(day in date_str for day in ['Thu', 'Fri', 'Mon', 'Tue', 'Wed', 'Sat', 'Sun']):
                date_str = re.sub(r'\s+\+\d{4}', '', date_str)
                dt = datetime.strptime(date_str, '%a %b %d %H:%M:%S %Y')
                start_dt = datetime.strptime(self.start_date, '%Y-%m-%d')
                end_dt = datetime.strptime(self.end_date, '%Y-%m-%d')
                return start_dt <= dt <= end_dt
            return True
        except:
            return True

    def matches_keywords(self, text):
        """æ£€æŸ¥æ–‡æœ¬æ˜¯å¦åŒ…å«å…³é”®è¯"""
        if not self.keywords:  # å¦‚æœæ²¡æœ‰è®¾ç½®å…³é”®è¯ï¼Œè¿”å›Trueï¼ˆä¸è¿‡æ»¤ï¼‰
            return True
        
        text = text.lower()
        for keyword in self.keywords:
            if keyword.lower() in text:
                return True
        return False

    def decode_text(self, text):
        """è§£ç Unicodeæ–‡æœ¬"""
        if not text:
            return ""
        try:
            if '\\u' in text:
                decoded = json.loads(f'"{text}"')
                return decoded
            return text
        except:
            return text

    def clean_html(self, text):
        """æ¸…ç†HTMLæ ‡ç­¾"""
        if not text:
            return ""
        text = re.sub(r'<br\s*/?>', '\n', text)
        text = re.sub(r'<[^>]+>', '', text)
        return self.decode_text(text).strip()

    def get_full_text(self, weibo_id):
        """è·å–å¾®åšå…¨æ–‡"""
        full_text_url = f"https://m.weibo.cn/statuses/extend?id={weibo_id}"
        try:
            req = urllib.request.Request(full_text_url, headers=self.headers)
            response = urllib.request.urlopen(req, timeout=15, context=self.ssl_context)
            content = response.read().decode('utf-8')
            data = json.loads(content)
            if data.get('ok') == 1:
                full_text = data.get('data', {}).get('longTextContent', '')
                if full_text:
                    return self.clean_html(full_text)
        except Exception as e:
            print(f"è·å–å…¨æ–‡å¤±è´¥: {e}")
        return None

    def download_image(self, image_url, weibo_id, image_index):
        """ä¸‹è½½å›¾ç‰‡"""
        try:
            if '.jpg' in image_url:
                ext = 'jpg'
            elif '.png' in image_url:
                ext = 'png'
            elif '.gif' in image_url:
                ext = 'gif'
            else:
                ext = 'jpg'
            
            filename = f"{weibo_id}_{image_index}.{ext}"
            filepath = os.path.join(self.images_dir, filename)
            
            if os.path.exists(filepath):
                return filepath
            
            req = urllib.request.Request(image_url, headers=self.headers)
            response = urllib.request.urlopen(req, timeout=15, context=self.ssl_context)
            
            with open(filepath, 'wb') as f:
                f.write(response.read())
            
            print(f"âœ… ä¸‹è½½å›¾ç‰‡: {filename}")
            self.stats['images_downloaded'] += 1
            return filepath
            
        except Exception as e:
            print(f"âŒ ä¸‹è½½å›¾ç‰‡å¤±è´¥: {e}")
            return None

    def scrape_weibos(self, progress_callback=None):
        """çˆ¬å–å¾®åšå†…å®¹"""
        all_weibos = []
        page = 1
        
        print(f"ğŸš€ å¼€å§‹æœé›† {self.user_name} çš„å¾®åš...")
        print(f"ğŸ“… æ—¶é—´èŒƒå›´: {self.start_date} åˆ° {self.end_date}")
        if self.keywords:
            print(f"ğŸ” å…³é”®è¯ç­›é€‰: {', '.join(self.keywords)}")
        
        while page <= self.max_pages:
            if progress_callback:
                progress_callback(
                    int((page - 1) / self.max_pages * 100),
                    f"æ­£åœ¨è·å–ç¬¬ {page} é¡µ..."
                )
            
            print(f"\nğŸ“– æ­£åœ¨è·å–ç¬¬ {page} é¡µ...")
            
            # è·å–å¾®åšåˆ—è¡¨
            url = f"https://m.weibo.cn/api/container/getIndex?type=uid&value={self.user_id}&containerid=107603{self.user_id}&page={page}"
            
            try:
                req = urllib.request.Request(url, headers=self.headers)
                response = urllib.request.urlopen(req, timeout=30, context=self.ssl_context)
                content = response.read().decode('utf-8')
                data = json.loads(content)
                
                if data.get('ok') != 1:
                    print(f"âŒ ç¬¬ {page} é¡µè·å–å¤±è´¥")
                    break
                
                cards = data.get('data', {}).get('cards', [])
                if not cards:
                    print(f"ğŸ“ ç¬¬ {page} é¡µæ²¡æœ‰æ›´å¤šå†…å®¹")
                    break
                
                page_weibos = 0
                for card in cards:
                    if card.get('card_type') == 9:
                        mblog = card.get('mblog', {})
                        if mblog:
                            self.stats['total_weibos'] += 1
                            
                            created_at = mblog.get('created_at', '')
                            
                            # æ£€æŸ¥æ—¶é—´èŒƒå›´
                            if not self.is_in_date_range(created_at):
                                continue
                            
                            weibo_id = mblog.get('id', '')
                            
                            # è·å–æ–‡æœ¬
                            raw_text = mblog.get('text', '')
                            clean_text = self.clean_html(raw_text)
                            
                            # æ£€æŸ¥æ˜¯å¦éœ€è¦è·å–å…¨æ–‡
                            if mblog.get('isLongText', False) or 'å…¨æ–‡' in clean_text:
                                print(f"ğŸ“ è·å–å¾®åš {weibo_id} çš„å…¨æ–‡...")
                                full_text = self.get_full_text(weibo_id)
                                if full_text:
                                    clean_text = full_text
                                    print(f"âœ… å…¨æ–‡è·å–æˆåŠŸ: {len(full_text)} å­—ç¬¦")
                            
                            # å¤„ç†è½¬å‘å†…å®¹æ–‡æœ¬ï¼ˆç”¨äºå…³é”®è¯åŒ¹é…ï¼‰
                            full_content_for_matching = clean_text
                            if 'retweeted_status' in mblog:
                                rt = mblog['retweeted_status']
                                rt_text = self.clean_html(rt.get('text', ''))
                                rt_id = rt.get('id', '')
                                
                                if rt.get('isLongText', False) or 'å…¨æ–‡' in rt_text:
                                    rt_full_text = self.get_full_text(rt_id)
                                    if rt_full_text:
                                        rt_text = rt_full_text
                                
                                full_content_for_matching += " " + rt_text
                            
                            # å…³é”®è¯ç­›é€‰
                            if not self.matches_keywords(full_content_for_matching):
                                continue
                            
                            self.stats['keyword_matches'] += 1
                            
                            weibo_data = {
                                'id': weibo_id,
                                'mid': mblog.get('mid', ''),
                                'created_at': created_at,
                                'text': clean_text,
                                'source': self.clean_html(mblog.get('source', '')),
                                'reposts_count': mblog.get('reposts_count', 0),
                                'comments_count': mblog.get('comments_count', 0),
                                'attitudes_count': mblog.get('attitudes_count', 0),
                                'url': f"https://m.weibo.cn/detail/{weibo_id}",
                            }
                            
                            # å¤„ç†å›¾ç‰‡
                            if 'pics' in mblog and mblog['pics']:
                                weibo_data['images'] = []
                                for i, pic in enumerate(mblog['pics'], 1):
                                    pic_url = pic.get('large', {}).get('url', '')
                                    if pic_url:
                                        weibo_data['images'].append(pic_url)
                                        self.download_image(pic_url, weibo_id, i)
                            
                            # å¤„ç†è½¬å‘å†…å®¹
                            if 'retweeted_status' in mblog:
                                rt = mblog['retweeted_status']
                                rt_text = self.clean_html(rt.get('text', ''))
                                rt_id = rt.get('id', '')
                                
                                if rt.get('isLongText', False) or 'å…¨æ–‡' in rt_text:
                                    rt_full_text = self.get_full_text(rt_id)
                                    if rt_full_text:
                                        rt_text = rt_full_text
                                
                                weibo_data['retweeted'] = {
                                    'user_name': rt.get('user', {}).get('screen_name', ''),
                                    'text': rt_text
                                }
                                
                                # ä¸‹è½½è½¬å‘å†…å®¹çš„å›¾ç‰‡
                                if 'pics' in rt and rt['pics']:
                                    for i, pic in enumerate(rt['pics'], 1):
                                        pic_url = pic.get('large', {}).get('url', '')
                                        if pic_url:
                                            self.download_image(pic_url, weibo_id, f"rt_{i}")
                            
                            all_weibos.append(weibo_data)
                            page_weibos += 1
                            self.stats['filtered_weibos'] += 1
                
                print(f"âœ… ç¬¬ {page} é¡µè·å–åˆ° {page_weibos} æ¡ç¬¦åˆæ¡ä»¶çš„å¾®åš")
                
                if page_weibos == 0:
                    print("ğŸ“ æ²¡æœ‰æ›´å¤šç¬¦åˆæ¡ä»¶çš„å¾®åš")
                    break
                
                self.stats['pages_processed'] = page
                page += 1
                
                if page <= self.max_pages:
                    time.sleep(self.request_delay)
                
            except Exception as e:
                print(f"âŒ ç¬¬ {page} é¡µè·å–å¤±è´¥: {e}")
                break
        
        print(f"\nğŸ‰ æœé›†å®Œæˆï¼")
        print(f"ğŸ“Š æ€»å…±å¤„ç†äº† {self.stats['total_weibos']} æ¡å¾®åš")
        print(f"ğŸ“Š ç­›é€‰åå¾—åˆ° {self.stats['filtered_weibos']} æ¡å¾®åš")
        print(f"ğŸ“Š ä¸‹è½½äº† {self.stats['images_downloaded']} å¼ å›¾ç‰‡")
        if self.keywords:
            print(f"ğŸ“Š å…³é”®è¯åŒ¹é… {self.stats['keyword_matches']} æ¡")
        
        if progress_callback:
            progress_callback(100, f"çˆ¬å–å®Œæˆï¼è·å–åˆ° {len(all_weibos)} æ¡å¾®åš")
        
        return all_weibos

    def generate_reports(self, weibos):
        """ç”ŸæˆæŠ¥å‘Šæ–‡ä»¶"""
        print("ğŸ“ ç”ŸæˆæŠ¥å‘Šæ–‡ä»¶...")
        
        # æ–‡ä»¶ååŒ…å«æ—¶é—´èŒƒå›´å’Œå…³é”®è¯ä¿¡æ¯
        date_range = f"{self.start_date.replace('-', '')}-{self.end_date.replace('-', '')}"
        keyword_suffix = f"_{'_'.join(self.keywords[:3])}" if self.keywords else ""
        
        base_filename = f"{self.user_name}_å¾®åšå†…å®¹_{date_range}{keyword_suffix}"
        md_filename = os.path.join(self.reports_dir, f"{base_filename}.md")
        html_filename = os.path.join(self.reports_dir, f"{base_filename}.html")
        
        # ç”ŸæˆMarkdownæŠ¥å‘Š
        self.generate_markdown_report(weibos, md_filename)
        
        # ç”ŸæˆHTMLæŠ¥å‘Š
        self.generate_html_report(weibos, html_filename, md_filename)
        
        # åˆ›å»ºå®Œæ•´å‹ç¼©åŒ…ï¼ˆåŒ…å«reportså’Œimagesæ–‡ä»¶å¤¹ï¼‰
        complete_package = self.create_complete_package(md_filename, html_filename)
        
        return {
            'markdown_file': md_filename,
            'html_file': html_filename,
            'complete_package': complete_package,
            'weibo_count': len(weibos),
            'image_count': self.stats['images_downloaded'],
            'keyword_matches': self.stats['keyword_matches']
        }

    def generate_markdown_report(self, weibos, filename):
        """ç”ŸæˆMarkdownæŠ¥å‘Š"""
        with open(filename, 'w', encoding='utf-8') as f:
            f.write(f"# {self.user_name} - å¾®åšå†…å®¹æŠ¥å‘Š\n")
            f.write(f"**æ—¶é—´èŒƒå›´**: {self.start_date} è‡³ {self.end_date}\n")
            if self.keywords:
                f.write(f"**å…³é”®è¯ç­›é€‰**: {', '.join(self.keywords)}\n")
            f.write("\n")
            
            f.write("## ğŸ“Š æ•°æ®ç»Ÿè®¡\n\n")
            f.write(f"- **ç”¨æˆ·**: {self.user_name}\n")
            f.write(f"- **å¾®åšæ€»æ•°**: {len(weibos)} æ¡\n")
            f.write(f"- **å›¾ç‰‡æ€»æ•°**: {self.stats['images_downloaded']} å¼ \n")
            if self.keywords:
                f.write(f"- **å…³é”®è¯åŒ¹é…**: {self.stats['keyword_matches']} æ¡\n")
            f.write(f"- **æŠ¥å‘Šç”Ÿæˆ**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            
            f.write("---\n\n")
            
            if weibos:
                f.write("## ğŸ“ å¾®åšå†…å®¹ (å®Œæ•´ç‰ˆ)\n\n")
                
                for i, weibo in enumerate(weibos, 1):
                    f.write(f"### å¾®åš {i}\n\n")
                    
                    # åŸºæœ¬ä¿¡æ¯
                    created_at = weibo.get('created_at', '')
                    chinese_date = self.format_chinese_date(created_at)
                    f.write(f"**ğŸ•’ å‘å¸ƒæ—¶é—´**: {chinese_date}\n")
                    f.write(f"**ğŸ”— å¾®åšé“¾æ¥**: {weibo.get('url', '')}\n")
                    f.write(f"**ğŸ†” å¾®åšID**: {weibo.get('id', '')}\n\n")
                    
                    # å®Œæ•´å†…å®¹
                    text = weibo.get('text', '').strip()
                    if text:
                        f.write(f"**ğŸ“„ å®Œæ•´å†…å®¹**:\n\n{text}\n\n")
                    
                    # è½¬å‘å†…å®¹
                    if 'retweeted' in weibo:
                        rt = weibo['retweeted']
                        f.write(f"**ğŸ”„ è½¬å‘å†…å®¹**:\n")
                        f.write(f"> **@{rt.get('user_name', '')}**: {rt.get('text', '')}\n\n")
                    
                    # å›¾ç‰‡å±•ç¤º
                    if 'images' in weibo and weibo['images']:
                        for idx, img_url in enumerate(weibo['images'], 1):
                            weibo_id = weibo.get('id', '')
                            local_pattern = os.path.join(self.images_dir, f"{weibo_id}_{idx}.jpg")
                            if os.path.exists(local_pattern):
                                relative_path = f"../images/{weibo_id}_{idx}.jpg"
                                f.write(f"![å›¾ç‰‡{idx}]({relative_path})\n\n")
                            
                            rt_pattern = os.path.join(self.images_dir, f"{weibo_id}_rt_{idx}.jpg")
                            if os.path.exists(rt_pattern):
                                relative_rt_path = f"../images/{weibo_id}_rt_{idx}.jpg"
                                f.write(f"![è½¬å‘å›¾ç‰‡{idx}]({relative_rt_path})\n\n")
                    
                    # äº’åŠ¨æ•°æ®
                    f.write(f"**ğŸ“Š äº’åŠ¨æ•°æ®**:\n")
                    f.write(f"- ğŸ”„ è½¬å‘: {weibo.get('reposts_count', 0):,}\n")
                    f.write(f"- ğŸ’¬ è¯„è®º: {weibo.get('comments_count', 0):,}\n")
                    f.write(f"- â¤ï¸ ç‚¹èµ: {weibo.get('attitudes_count', 0):,}\n")
                    
                    if weibo.get('source'):
                        f.write(f"- ğŸ“± æ¥æº: {weibo.get('source', '')}\n")
                    
                    f.write(f"\n---\n\n")
        
        print(f"âœ… MarkdownæŠ¥å‘Šå·²ç”Ÿæˆ: {filename}")

    def generate_html_report(self, weibos, html_filename, md_filename):
        """ç”ŸæˆHTMLæŠ¥å‘Šï¼Œå›¾ç‰‡ä»¥base64åµŒå…¥"""
        print(f"ğŸ“ ç”ŸæˆHTMLæŠ¥å‘Š: {html_filename}")
        
        def image_to_base64(image_path):
            """å°†å›¾ç‰‡è½¬æ¢ä¸ºbase64ç¼–ç """
            try:
                with open(image_path, 'rb') as f:
                    return base64.b64encode(f.read()).decode('utf-8')
            except:
                return None
        
        # HTMLæ¨¡æ¿
        html_template = """<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>{title}</title>
    <style>
        body {{
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', 'PingFang SC', sans-serif;
            line-height: 1.6;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            background-color: #fff;
        }}
        h1 {{ color: #2c3e50; border-bottom: 2px solid #3498db; padding-bottom: 10px; }}
        h2 {{ color: #34495e; margin-top: 30px; }}
        h3 {{ color: #7f8c8d; margin-top: 25px; }}
        .weibo-content {{ 
            background-color: #f8f9fa; 
            padding: 15px; 
            border-radius: 8px; 
            margin: 15px 0;
            border-left: 4px solid #3498db;
        }}
        .weibo-meta {{ 
            color: #7f8c8d; 
            font-size: 0.9em; 
            margin-bottom: 10px;
        }}
        .weibo-text {{ 
            margin: 15px 0; 
            white-space: pre-line;
        }}
        .retweet {{ 
            background-color: #ecf0f1; 
            padding: 10px; 
            border-radius: 5px; 
            margin: 10px 0;
            border-left: 3px solid #95a5a6;
        }}
        .stats {{ 
            background-color: #fff; 
            padding: 10px; 
            border-radius: 5px; 
            border: 1px solid #bdc3c7;
            margin-top: 15px;
        }}
        .stats ul {{ margin: 0; padding-left: 20px; }}
        img {{ 
            max-width: 100%; 
            height: auto; 
            border-radius: 8px; 
            margin: 10px 0;
            box-shadow: 0 2px 8px rgba(0,0,0,0.1);
        }}
        hr {{ border: none; border-top: 1px solid #ecf0f1; margin: 30px 0; }}
        .summary {{ 
            background-color: #e8f5e8; 
            padding: 15px; 
            border-radius: 8px; 
            margin: 20px 0;
        }}
        blockquote {{ 
            margin: 0; 
            padding-left: 15px; 
            color: #7f8c8d;
        }}
    </style>
</head>
<body>
{content}
</body>
</html>"""
        
        # ç”ŸæˆHTMLå†…å®¹
        html_content = f"<h1>{self.user_name} - å¾®åšå†…å®¹æŠ¥å‘Š</h1>\n"
        html_content += f"<p><strong>æ—¶é—´èŒƒå›´</strong>: {self.start_date} è‡³ {self.end_date}</p>\n"
        if self.keywords:
            html_content += f"<p><strong>å…³é”®è¯ç­›é€‰</strong>: {', '.join(self.keywords)}</p>\n"
        html_content += "\n"
        
        html_content += "<h2>ğŸ“Š æ•°æ®ç»Ÿè®¡</h2>\n"
        html_content += "<ul>\n"
        html_content += f"<li><strong>ç”¨æˆ·</strong>: {self.user_name}</li>\n"
        html_content += f"<li><strong>å¾®åšæ€»æ•°</strong>: {len(weibos)} æ¡</li>\n"
        html_content += f"<li><strong>å›¾ç‰‡æ€»æ•°</strong>: {self.stats['images_downloaded']} å¼ </li>\n"
        if self.keywords:
            html_content += f"<li><strong>å…³é”®è¯åŒ¹é…</strong>: {self.stats['keyword_matches']} æ¡</li>\n"
        html_content += f"<li><strong>æŠ¥å‘Šç”Ÿæˆ</strong>: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</li>\n"
        html_content += "</ul>\n"
        
        html_content += "<hr>\n"
        
        if weibos:
            html_content += "<h2>ğŸ“ å¾®åšå†…å®¹ (å®Œæ•´ç‰ˆ)</h2>\n"
            
            for i, weibo in enumerate(weibos, 1):
                html_content += f"<h3>å¾®åš {i}</h3>\n"
                html_content += "<div class='weibo-content'>\n"
                
                # åŸºæœ¬ä¿¡æ¯
                created_at = weibo.get('created_at', '')
                chinese_date = self.format_chinese_date(created_at)
                html_content += f"<p class='weibo-meta'><strong>ğŸ•’ å‘å¸ƒæ—¶é—´</strong>: {chinese_date}</p>\n"
                html_content += f"<p class='weibo-meta'><strong>ğŸ”— å¾®åšé“¾æ¥</strong>: <a href='{weibo.get('url', '')}' target='_blank'>{weibo.get('url', '')}</a></p>\n"
                html_content += f"<p class='weibo-meta'><strong>ğŸ†” å¾®åšID</strong>: {weibo.get('id', '')}</p>\n"
                
                # å®Œæ•´å†…å®¹
                text = weibo.get('text', '').strip()
                if text:
                    html_content += f"<div class='weibo-text'><strong>ğŸ“„ å®Œæ•´å†…å®¹</strong>:<br>{text}</div>\n"
                
                # è½¬å‘å†…å®¹
                if 'retweeted' in weibo:
                    rt = weibo['retweeted']
                    html_content += "<div class='retweet'>\n"
                    html_content += f"<strong>ğŸ”„ è½¬å‘å†…å®¹</strong>:<br>\n"
                    html_content += f"<blockquote><strong>@{rt.get('user_name', '')}</strong>: {rt.get('text', '')}</blockquote>\n"
                    html_content += "</div>\n"
                
                # å›¾ç‰‡å±•ç¤ºï¼ˆbase64åµŒå…¥ï¼‰
                if 'images' in weibo and weibo['images']:
                    for idx, img_url in enumerate(weibo['images'], 1):
                        weibo_id = weibo.get('id', '')
                        local_pattern = os.path.join(self.images_dir, f"{weibo_id}_{idx}.jpg")
                        if os.path.exists(local_pattern):
                            base64_data = image_to_base64(local_pattern)
                            if base64_data:
                                html_content += f'<img src="data:image/jpeg;base64,{base64_data}" alt="å›¾ç‰‡{idx}" />\n'
                        
                        # æ£€æŸ¥è½¬å‘å›¾ç‰‡
                        rt_pattern = os.path.join(self.images_dir, f"{weibo_id}_rt_{idx}.jpg")
                        if os.path.exists(rt_pattern):
                            base64_data = image_to_base64(rt_pattern)
                            if base64_data:
                                html_content += f'<img src="data:image/jpeg;base64,{base64_data}" alt="è½¬å‘å›¾ç‰‡{idx}" />\n'
                
                # äº’åŠ¨æ•°æ®
                html_content += "<div class='stats'>\n"
                html_content += "<strong>ğŸ“Š äº’åŠ¨æ•°æ®</strong>:\n"
                html_content += "<ul>\n"
                html_content += f"<li>ğŸ”„ è½¬å‘: {weibo.get('reposts_count', 0):,}</li>\n"
                html_content += f"<li>ğŸ’¬ è¯„è®º: {weibo.get('comments_count', 0):,}</li>\n"
                html_content += f"<li>â¤ï¸ ç‚¹èµ: {weibo.get('attitudes_count', 0):,}</li>\n"
                if weibo.get('source'):
                    html_content += f"<li>ğŸ“± æ¥æº: {weibo.get('source', '')}</li>\n"
                html_content += "</ul>\n"
                html_content += "</div>\n"
                
                html_content += "</div>\n"
                html_content += "<hr>\n"
        
        # ç”Ÿæˆæœ€ç»ˆHTML
        title = f"{self.user_name} - å¾®åšå†…å®¹æŠ¥å‘Š ({self.start_date} è‡³ {self.end_date})"
        final_html = html_template.format(title=title, content=html_content)
        
        # å†™å…¥HTMLæ–‡ä»¶
        with open(html_filename, 'w', encoding='utf-8') as f:
            f.write(final_html)
        
        print(f"âœ… HTMLæŠ¥å‘Šå·²ç”Ÿæˆ: {html_filename}")

    def create_complete_package(self, md_filename, html_filename):
        """åˆ›å»ºå®Œæ•´çš„ç»“æœå‹ç¼©åŒ…ï¼ŒåŒ…å«reportså’Œimagesæ–‡ä»¶å¤¹"""
        package_name = f"{self.user_name}_{self.start_date.replace('-', '')}-{self.end_date.replace('-', '')}"
        zip_filename = os.path.join(self.output_dir, f"{package_name}.zip")
        
        print(f"ğŸ“¦ åˆ›å»ºå®Œæ•´å‹ç¼©åŒ…: {zip_filename}")
        
        with zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:
            # æ·»åŠ reportsæ–‡ä»¶å¤¹
            if os.path.exists(md_filename):
                arcname = f"reports/{os.path.basename(md_filename)}"
                zipf.write(md_filename, arcname)
                print(f"   ğŸ“„ æ·»åŠ MarkdownæŠ¥å‘Š: {arcname}")
            
            if os.path.exists(html_filename):
                arcname = f"reports/{os.path.basename(html_filename)}"
                zipf.write(html_filename, arcname)
                print(f"   ğŸ“„ æ·»åŠ HTMLæŠ¥å‘Š: {arcname}")
            
            # æ·»åŠ imagesæ–‡ä»¶å¤¹
            if os.path.exists(self.images_dir):
                for root, dirs, files in os.walk(self.images_dir):
                    for file in files:
                        if file.endswith(('.jpg', '.png', '.gif', '.webp')):
                            file_path = os.path.join(root, file)
                            # ä½¿ç”¨ç›¸å¯¹è·¯å¾„ï¼Œä¿æŒimages/æ–‡ä»¶åæ ¼å¼
                            arcname = f"images/{file}"
                            zipf.write(file_path, arcname)
                
                print(f"   ğŸ–¼ï¸ æ·»åŠ å›¾ç‰‡æ–‡ä»¶: {self.stats['images_downloaded']} å¼ ")
            
            # ä¿®å¤æŠ¥å‘Šä¸­çš„å›¾ç‰‡è·¯å¾„ä¸ºç›¸å¯¹è·¯å¾„
            self.fix_image_paths_in_zip(zipf, md_filename, html_filename)
        
        print(f"âœ… å®Œæ•´å‹ç¼©åŒ…å·²ç”Ÿæˆ: {zip_filename}")
        return zip_filename
    
    def fix_image_paths_in_zip(self, zipf, md_filename, html_filename):
        """ä¿®å¤å‹ç¼©åŒ…ä¸­æŠ¥å‘Šæ–‡ä»¶çš„å›¾ç‰‡è·¯å¾„"""
        # ä¿®å¤Markdownæ–‡ä»¶ä¸­çš„å›¾ç‰‡è·¯å¾„
        if os.path.exists(md_filename):
            with open(md_filename, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # å°†ç›¸å¯¹è·¯å¾„æ”¹ä¸ºå‹ç¼©åŒ…å†…çš„è·¯å¾„
            content = re.sub(r'!\[(.*?)\]\(\.\./images/(.*?\.jpg)\)', r'![\1](images/\2)', content)
            
            # å†™å…¥ä¿®å¤åçš„æ–‡ä»¶åˆ°å‹ç¼©åŒ…
            zipf.writestr(f"reports/{os.path.basename(md_filename)}", content)
        
        # æ³¨æ„ï¼šHTMLæ–‡ä»¶ä½¿ç”¨base64åµŒå…¥å›¾ç‰‡ï¼Œä¸éœ€è¦ä¿®å¤è·¯å¾„


def scrape_weibo_web(params, progress_callback=None):
    """Webæ¥å£è°ƒç”¨çš„çˆ¬è™«å‡½æ•°"""
    scraper = WebWeiboScraper(
        user_id=params['userId'],
        user_name=params['userName'],
        start_date=params['startDate'],
        end_date=params['endDate'],
        keywords=params.get('keywords', []),
        max_pages=params.get('maxPages', 10),
        request_delay=params.get('requestDelay', 2),
        output_dir="weibo_output"
    )
    
    # çˆ¬å–å¾®åš
    weibos = scraper.scrape_weibos(progress_callback)
    
    # ç”ŸæˆæŠ¥å‘Š
    result = scraper.generate_reports(weibos)
    
    return result


if __name__ == "__main__":
    # æµ‹è¯•ç”¨ä¾‹
    test_params = {
        'userId': '1317335037',
        'userName': 'å§œæ±ç¥¥',
        'startDate': '2025-03-01',
        'endDate': '2025-09-01',
        'keywords': ['æŠ–éŸ³', 'åˆ›æ–°'],  # æµ‹è¯•å…³é”®è¯ç­›é€‰
        'maxPages': 3,
        'requestDelay': 2
    }
    
    result = scrape_weibo_web(test_params)
    print("æµ‹è¯•å®Œæˆ:", result)