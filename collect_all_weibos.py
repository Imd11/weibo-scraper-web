#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æœé›†æŒ‡å®šæ—¶é—´èŒƒå›´å†…çš„æ‰€æœ‰å¾®åš - åŸºäºå¯å·¥ä½œçš„æŠ¥å‘Šç”Ÿæˆå™¨æ‰©å±•
"""

import ssl
import urllib.request
import json
import re
import os
import glob
from datetime import datetime
import codecs
import time
from config import WEIBO_USER_ID, USER_NAME, OUTPUT_DIR, START_DATE, END_DATE


def format_chinese_date(date_str):
    """å°†æ—¥æœŸè½¬æ¢ä¸ºä¸­æ–‡æ ¼å¼"""
    try:
        # å¤„ç†å¾®åšçš„æ—¶é—´æ ¼å¼ï¼Œå¦‚: "Thu Apr 24 18:05:55 +0800 2025"
        if any(day in date_str for day in ['Thu', 'Fri', 'Mon', 'Tue', 'Wed', 'Sat', 'Sun']):
            # å»æ‰æ—¶åŒºä¿¡æ¯
            date_str = re.sub(r'\s+\+\d{4}', '', date_str)
            # è§£ææ—¶é—´
            dt = datetime.strptime(date_str, '%a %b %d %H:%M:%S %Y')
            return f"{dt.year}å¹´{dt.month}æœˆ{dt.day}æ—¥"
        # å¤„ç†å…¶ä»–æ—¶é—´æ ¼å¼
        else:
            return date_str
    except:
        return date_str


def is_in_date_range(date_str, start_date, end_date):
    """æ£€æŸ¥æ—¥æœŸæ˜¯å¦åœ¨æŒ‡å®šèŒƒå›´å†…"""
    try:
        if any(day in date_str for day in ['Thu', 'Fri', 'Mon', 'Tue', 'Wed', 'Sat', 'Sun']):
            date_str = re.sub(r'\s+\+\d{4}', '', date_str)
            dt = datetime.strptime(date_str, '%a %b %d %H:%M:%S %Y')
            start_dt = datetime.strptime(start_date, '%Y-%m-%d')
            end_dt = datetime.strptime(end_date, '%Y-%m-%d')
            return start_dt <= dt <= end_dt
        return True  # å¯¹äºæ— æ³•è§£æçš„æ—¶é—´ï¼Œé»˜è®¤åŒ…å«
    except:
        return True


def download_image(image_url, weibo_id, image_index, images_dir):
    """ä¸‹è½½å›¾ç‰‡"""
    try:
        # ç¡®ä¿å›¾ç‰‡ç›®å½•å­˜åœ¨
        os.makedirs(images_dir, exist_ok=True)
        
        # è·å–å›¾ç‰‡æ‰©å±•å
        if '.jpg' in image_url:
            ext = 'jpg'
        elif '.png' in image_url:
            ext = 'png'
        elif '.gif' in image_url:
            ext = 'gif'
        else:
            ext = 'jpg'
        
        filename = f"{weibo_id}_{image_index}.{ext}"
        filepath = os.path.join(images_dir, filename)
        
        # å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡ä¸‹è½½
        if os.path.exists(filepath):
            return filepath
        
        # ä¸‹è½½å›¾ç‰‡
        headers = {
            'User-Agent': 'Mozilla/5.0 (iPhone; CPU iPhone OS 15_0 like Mac OS X) AppleWebKit/605.1.15',
            'Referer': 'https://m.weibo.cn/',
        }
        
        req = urllib.request.Request(image_url, headers=headers)
        ssl_context = ssl.create_default_context()
        ssl_context.check_hostname = False
        ssl_context.verify_mode = ssl.CERT_NONE
        
        response = urllib.request.urlopen(req, timeout=15, context=ssl_context)
        
        with open(filepath, 'wb') as f:
            f.write(response.read())
        
        print(f"âœ… ä¸‹è½½å›¾ç‰‡: {filename}")
        return filepath
        
    except Exception as e:
        print(f"âŒ ä¸‹è½½å›¾ç‰‡å¤±è´¥: {e}")
        return None


def collect_all_weibos():
    """æœé›†æ‰€æœ‰å¾®åš"""
    ssl_context = ssl.create_default_context()
    ssl_context.check_hostname = False
    ssl_context.verify_mode = ssl.CERT_NONE
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (iPhone; CPU iPhone OS 15_0 like Mac OS X) AppleWebKit/605.1.15',
        'Accept': 'application/json, text/plain, */*',
        'Referer': f'https://m.weibo.cn/u/{WEIBO_USER_ID}',
    }
    
    def decode_text(text):
        if not text:
            return ""
        try:
            if '\\u' in text:
                decoded = json.loads(f'"{text}"')
                return decoded
            return text
        except:
            return text
    
    def clean_html(text):
        if not text:
            return ""
        text = re.sub(r'<br\s*/?>', '\n', text)
        text = re.sub(r'<[^>]+>', '', text)
        return decode_text(text).strip()
    
    def get_full_text(weibo_id):
        """è·å–å¾®åšå…¨æ–‡"""
        full_text_url = f"https://m.weibo.cn/statuses/extend?id={weibo_id}"
        try:
            req = urllib.request.Request(full_text_url, headers=headers)
            response = urllib.request.urlopen(req, timeout=15, context=ssl_context)
            content = response.read().decode('utf-8')
            data = json.loads(content)
            if data.get('ok') == 1:
                full_text = data.get('data', {}).get('longTextContent', '')
                if full_text:
                    return clean_html(full_text)
        except Exception as e:
            print(f"è·å–å…¨æ–‡å¤±è´¥: {e}")
        return None
    
    all_weibos = []
    page = 1
    max_pages = 10  # é™åˆ¶æœ€å¤§é¡µæ•°é˜²æ­¢æ— é™å¾ªç¯
    images_dir = f"{OUTPUT_DIR}/images"
    
    print(f"ğŸš€ å¼€å§‹æœé›† {USER_NAME} çš„å¾®åš...")
    print(f"ğŸ“… æ—¶é—´èŒƒå›´: {START_DATE} åˆ° {END_DATE}")
    
    while page <= max_pages:
        print(f"\nğŸ“– æ­£åœ¨è·å–ç¬¬ {page} é¡µ...")
        
        # è·å–å¾®åšåˆ—è¡¨
        url = f"https://m.weibo.cn/api/container/getIndex?type=uid&value={WEIBO_USER_ID}&containerid=107603{WEIBO_USER_ID}&page={page}"
        
        try:
            req = urllib.request.Request(url, headers=headers)
            response = urllib.request.urlopen(req, timeout=30, context=ssl_context)
            content = response.read().decode('utf-8')
            data = json.loads(content)
            
            if data.get('ok') != 1:
                print(f"âŒ ç¬¬ {page} é¡µè·å–å¤±è´¥")
                break
            
            cards = data.get('data', {}).get('cards', [])
            if not cards:
                print(f"ğŸ“ ç¬¬ {page} é¡µæ²¡æœ‰æ›´å¤šå†…å®¹")
                break
            
            page_weibos = 0
            for card in cards:
                if card.get('card_type') == 9:
                    mblog = card.get('mblog', {})
                    if mblog:
                        created_at = mblog.get('created_at', '')
                        
                        # æ£€æŸ¥æ—¶é—´èŒƒå›´
                        if not is_in_date_range(created_at, START_DATE, END_DATE):
                            continue
                        
                        weibo_id = mblog.get('id', '')
                        mid = mblog.get('mid', '')
                        
                        # è·å–æ–‡æœ¬
                        raw_text = mblog.get('text', '')
                        clean_text = clean_html(raw_text)
                        
                        # æ£€æŸ¥æ˜¯å¦éœ€è¦è·å–å…¨æ–‡
                        if mblog.get('isLongText', False) or 'å…¨æ–‡' in clean_text:
                            print(f"ğŸ“ è·å–å¾®åš {weibo_id} çš„å…¨æ–‡...")
                            full_text = get_full_text(weibo_id)
                            if full_text:
                                clean_text = full_text
                                print(f"âœ… å…¨æ–‡è·å–æˆåŠŸ: {len(full_text)} å­—ç¬¦")
                        
                        weibo_data = {
                            'id': weibo_id,
                            'mid': mid,
                            'created_at': created_at,
                            'text': clean_text,
                            'source': clean_html(mblog.get('source', '')),
                            'reposts_count': mblog.get('reposts_count', 0),
                            'comments_count': mblog.get('comments_count', 0),
                            'attitudes_count': mblog.get('attitudes_count', 0),
                            'url': f"https://m.weibo.cn/detail/{weibo_id}",
                        }
                        
                        # å¤„ç†å›¾ç‰‡
                        if 'pics' in mblog and mblog['pics']:
                            weibo_data['images'] = []
                            for i, pic in enumerate(mblog['pics'], 1):
                                pic_url = pic.get('large', {}).get('url', '')
                                if pic_url:
                                    weibo_data['images'].append(pic_url)
                                    # ä¸‹è½½å›¾ç‰‡
                                    download_image(pic_url, weibo_id, i, images_dir)
                        
                        # å¤„ç†è½¬å‘å†…å®¹
                        if 'retweeted_status' in mblog:
                            rt = mblog['retweeted_status']
                            rt_text = clean_html(rt.get('text', ''))
                            rt_id = rt.get('id', '')
                            
                            # æ£€æŸ¥è½¬å‘å†…å®¹æ˜¯å¦ä¹Ÿæœ‰å…¨æ–‡
                            if rt.get('isLongText', False) or 'å…¨æ–‡' in rt_text:
                                rt_full_text = get_full_text(rt_id)
                                if rt_full_text:
                                    rt_text = rt_full_text
                            
                            weibo_data['retweeted'] = {
                                'user_name': rt.get('user', {}).get('screen_name', ''),
                                'text': rt_text
                            }
                            
                            # ä¸‹è½½è½¬å‘å†…å®¹çš„å›¾ç‰‡
                            if 'pics' in rt and rt['pics']:
                                for i, pic in enumerate(rt['pics'], 1):
                                    pic_url = pic.get('large', {}).get('url', '')
                                    if pic_url:
                                        download_image(pic_url, weibo_id, f"rt_{i}", images_dir)
                        
                        all_weibos.append(weibo_data)
                        page_weibos += 1
            
            print(f"âœ… ç¬¬ {page} é¡µè·å–åˆ° {page_weibos} æ¡å¾®åš")
            
            if page_weibos == 0:
                print("ğŸ“ æ²¡æœ‰æ›´å¤šç¬¦åˆæ¡ä»¶çš„å¾®åš")
                break
            
            page += 1
            time.sleep(2)  # è¯·æ±‚é—´éš”
            
        except Exception as e:
            print(f"âŒ ç¬¬ {page} é¡µè·å–å¤±è´¥: {e}")
            break
    
    print(f"\nğŸ‰ æœé›†å®Œæˆï¼æ€»å…±è·å–åˆ° {len(all_weibos)} æ¡å¾®åš")
    return all_weibos


def generate_complete_report(weibos):
    """ç”Ÿæˆå®Œæ•´æŠ¥å‘Š"""
    # è·å–å·²ä¸‹è½½çš„å›¾ç‰‡
    image_files = glob.glob(f"{OUTPUT_DIR}/images/*.jpg")
    
    # ç¡®ä¿æŠ¥å‘Šç›®å½•å­˜åœ¨
    os.makedirs(f"{OUTPUT_DIR}/reports", exist_ok=True)
    
    # ç”Ÿæˆæ–‡ä»¶å
    date_range = f"{START_DATE.replace('-', '')}-{END_DATE.replace('-', '')}"
    filename = f"{OUTPUT_DIR}/reports/{USER_NAME}_å®Œæ•´å¾®åšå†…å®¹_{date_range}.md"
    
    print(f"ğŸ“ ç”Ÿæˆå®Œæ•´æŠ¥å‘Š: {filename}")
    
    with open(filename, 'w', encoding='utf-8') as f:
        f.write(f"# {USER_NAME} - å®Œæ•´å¾®åšå†…å®¹æŠ¥å‘Š\n")
        f.write(f"**æ—¶é—´èŒƒå›´**: {START_DATE} è‡³ {END_DATE}\n\n")
        
        f.write("## ğŸ“Š æ•°æ®ç»Ÿè®¡\n\n")
        f.write(f"- **ç”¨æˆ·**: {USER_NAME}\n")
        f.write(f"- **å¾®åšæ€»æ•°**: {len(weibos)} æ¡\n")
        f.write(f"- **å›¾ç‰‡æ€»æ•°**: {len(image_files)} å¼ \n")
        f.write(f"- **æŠ¥å‘Šç”Ÿæˆ**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        
        f.write("---\n\n")
        
        # å¾®åšå†…å®¹
        if weibos:
            f.write("## ğŸ“ å¾®åšå†…å®¹ (å®Œæ•´ç‰ˆ)\n\n")
            
            for i, weibo in enumerate(weibos, 1):
                f.write(f"### å¾®åš {i}\n\n")
                
                # åŸºæœ¬ä¿¡æ¯ - ä½¿ç”¨ä¸­æ–‡æ—¥æœŸæ ¼å¼
                created_at = weibo.get('created_at', '')
                chinese_date = format_chinese_date(created_at)
                f.write(f"**ğŸ•’ å‘å¸ƒæ—¶é—´**: {chinese_date}\n")
                f.write(f"**ğŸ”— å¾®åšé“¾æ¥**: {weibo.get('url', '')}\n")
                f.write(f"**ğŸ†” å¾®åšID**: {weibo.get('id', '')}\n\n")
                
                # å®Œæ•´å†…å®¹
                text = weibo.get('text', '').strip()
                if text:
                    f.write(f"**ğŸ“„ å®Œæ•´å†…å®¹**:\n\n{text}\n\n")
                
                # è½¬å‘å†…å®¹
                if 'retweeted' in weibo:
                    rt = weibo['retweeted']
                    f.write(f"**ğŸ”„ è½¬å‘å†…å®¹**:\n")
                    f.write(f"> **@{rt.get('user_name', '')}**: {rt.get('text', '')}\n\n")
                
                # å›¾ç‰‡å±•ç¤º - ç›´æ¥æ˜¾ç¤ºå›¾ç‰‡
                if 'images' in weibo and weibo['images']:
                    for idx, img_url in enumerate(weibo['images'], 1):
                        # æŸ¥æ‰¾å¯¹åº”çš„æœ¬åœ°æ–‡ä»¶
                        weibo_id = weibo.get('id', '')
                        local_pattern = f"{OUTPUT_DIR}/images/{weibo_id}_{idx}.jpg"
                        if os.path.exists(local_pattern):
                            # ä½¿ç”¨ç›¸å¯¹è·¯å¾„ - ä»reportsç›®å½•åˆ°imagesç›®å½•
                            relative_path = f"../images/{weibo_id}_{idx}.jpg"
                            f.write(f"![å›¾ç‰‡{idx}]({relative_path})\n\n")
                        
                        # æ£€æŸ¥è½¬å‘å›¾ç‰‡
                        rt_pattern = f"{OUTPUT_DIR}/images/{weibo_id}_rt_{idx}.jpg"
                        if os.path.exists(rt_pattern):
                            relative_rt_path = f"../images/{weibo_id}_rt_{idx}.jpg"
                            f.write(f"![è½¬å‘å›¾ç‰‡{idx}]({relative_rt_path})\n\n")
                
                # äº’åŠ¨æ•°æ®
                f.write(f"**ğŸ“Š äº’åŠ¨æ•°æ®**:\n")
                f.write(f"- ğŸ”„ è½¬å‘: {weibo.get('reposts_count', 0):,}\n")
                f.write(f"- ğŸ’¬ è¯„è®º: {weibo.get('comments_count', 0):,}\n")
                f.write(f"- â¤ï¸ ç‚¹èµ: {weibo.get('attitudes_count', 0):,}\n")
                
                if weibo.get('source'):
                    f.write(f"- ğŸ“± æ¥æº: {weibo.get('source', '')}\n")
                
                f.write(f"\n---\n\n")
    
    print(f"âœ… å®Œæ•´æŠ¥å‘Šå·²ç”Ÿæˆ: {filename}")
    return filename


if __name__ == "__main__":
    # æœé›†æ‰€æœ‰å¾®åš
    all_weibos = collect_all_weibos()
    
    # ç”Ÿæˆå®Œæ•´æŠ¥å‘Š
    if all_weibos:
        generate_complete_report(all_weibos)
    else:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„å¾®åš")