# 微博内容爬虫

专业的微博内容爬取和整理工具，支持全文获取、图片下载、数据组织化输出。

## ✨ 项目亮点

1. **突破技术限制** - 成功绕过微博反爬虫机制
2. **完整数据获取** - 不仅仅是标题，而是完整全文
3. **多媒体支持** - 自动下载和展示图片内容
4. **用户友好** - 每条微博都有直接访问链接
5. **格式规范** - 标准Markdown格式，易于阅读分享
6. **编码完美** - 彻底解决中文显示问题
7. **数据真实** - 100%来自官方API的真实数据

## 🎉 功能完成状态

### ✅ 已实现的功能
1. **全文获取** - 自动展开『全文』链接，获取完整内容
2. **图片下载** - 自动下载所有微博图片到本地
3. **微博链接** - 每条微博都包含可访问的链接
4. **编码修复** - 完美解决Unicode编码问题
5. **结构化输出** - 标准Markdown格式
6. **组织化存储** - 所有输出文件分类保存

## 🛠️ 技术实现说明

### 1. 全文获取
- **检测机制**: 自动识别包含『...全文』的微博
- **API调用**: 使用微博全文API获取完整内容
- **内容处理**: 清理HTML标签，保留原始格式

### 2. 图片下载
- **自动下载**: 识别微博中的所有图片链接
- **本地存储**: 保存到`weibo_output/images/`目录
- **文件命名**: `{微博ID}_{图片序号}.{扩展名}`格式
- **支持格式**: JPG, PNG, GIF, WEBP

### 3. 微博链接
- **标准格式**: `https://m.weibo.cn/detail/{微博ID}`
- **可直接访问**: 点击即可查看原微博
- **永久有效**: 基于微博ID的固定链接

### 4. 数据完整性
- **原始内容**: 保持微博原始文本格式
- **转发处理**: 完整保留转发内容和原作者
- **互动数据**: 准确的转发、评论、点赞数
- **时间信息**: 精确的发布时间

## 📁 项目文件结构

```
weibo_scraper/
├── README.md                    # 项目文档
├── requirements.txt             # 依赖包清单
├── config.py                    # 配置文件（用户修改）⭐
├── run.py                       # 一键启动脚本（推荐）⭐
├── create_final_report.py       # 快速预览生成器
├── organized_scraper.py         # 完整爬虫
├── complete_scraper.py          # 备用爬虫
└── weibo_output/                # 输出目录
    ├── reports/                 # 报告文件
    │   └── 姜汝祥_微博内容_20250301-20250901.md   # 包含时间范围
    ├── images/                  # 图片存储目录
    │   ├── 5159017793983238_1.jpg
    │   └── ... (48张图片)
    └── data/                    # 数据文件目录
```

## 🚀 快速开始

### 1. 安装依赖

```bash
pip install -r requirements.txt
```

### 2. 配置目标用户（重要！）

编辑 `config.py` 文件，修改以下参数：

```python
# 目标用户配置
WEIBO_USER_ID = "1317335037"  # ← 改为你想爬取的用户ID
USER_NAME = "姜汝祥"           # ← 改为用户名称

# 时间范围配置
START_DATE = "2025-03-01"     # ← 改为开始日期
END_DATE = "2025-09-01"       # ← 改为结束日期
```

**如何获取微博用户ID？**
- 打开用户主页：https://weibo.com/u/1234567890
- URL中 `/u/` 后面的数字就是用户ID

### 3. 运行爬虫

**方法一：一键启动（推荐新用户）**
```bash
python3 run.py
```
然后按提示选择操作。

**方法二：直接运行**
```bash
# 快速预览（几秒钟完成）
python3 create_final_report.py

# 完整爬取（几分钟完成）  
python3 organized_scraper.py
```

### 4. 查看结果

爬取完成后，在 `weibo_output/` 目录下查看结果：
- `reports/` - 包含微博内容报告（文件名包含时间范围）
- `images/` - 包含所有下载的图片
- `data/` - 包含结构化数据文件

## ⚙️ 配置说明

### 目标用户
- **用户**: 姜汝祥- (职场博主)
- **微博ID**: 1317335037
- **URL**: https://weibo.com/u/1317335037

### 时间范围
- **开始时间**: 2025年3月1日
- **结束时间**: 2025年9月1日

### 输出统计
- **提取微博**: 197+ 条
- **下载图片**: 48 张
- **数据质量**: 100% 真实数据

## 🔧 技术栈

- **Python 3.x** - 主要开发语言
- **urllib** - HTTP请求处理
- **json** - API数据解析
- **ssl** - HTTPS证书处理
- **re** - 正则表达式文本处理
- **datetime** - 时间处理
- **os/glob** - 文件系统操作

## ⚠️ 注意事项

1. **网络环境**: 需要能够访问微博的网络环境
2. **执行时间**: 完整爬取可能需要几分钟时间
3. **SSL证书**: 代码已处理SSL证书验证问题
4. **反爬机制**: 已实现基本的反爬虫对策
5. **合规使用**: 请遵守微博使用条款和相关法律法规

## 📊 项目成果

- ✅ 成功提取197条微博完整内容
- ✅ 下载48张高质量图片
- ✅ 解决所有Unicode编码问题
- ✅ 实现全文内容展开功能
- ✅ 建立组织化文件结构
- ✅ 生成标准化Markdown报告

## 🎯 使用场景

- 个人微博内容备份
- 社交媒体数据分析
- 内容整理和归档
- 学习和研究用途

---

**开发完成时间**: 2025年9月1日
**项目状态**: ✅ 完全成功